# 25.03.25 과제
```
1. 인공지능에서 지능에 해당하는 기능
- Decision Making, Classification, Prediction

2. 인공지능의 종류 3가지 .. 
- 지도학습 : Label이 주어진 상태로 학습하는 방식. (주로 회귀와 분류에 사용)
- 반지도학습 : 일부 데이터만 있는 상황에서 학습하는 방식.
- 강화학습 : 위 두 개와는 전혀 다른 종류의 알고리즘.
환경을 관찰하여 행동을 실행하고 보상을 받는다. (ex_ 알파고)

3. 전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?
- 전통적인 프로그래밍은 입력 -> 규칙 -> 출력 순인데 반면
인공지능 프로그래밍은 입력과 출력 -> 규칙 -> 새로운 입력을 도출하는 방식..
이것을 학습이라고 한다.
후자는 API의 규칙을 따르면 되는 것이므로 프로그래머의 수고를 덜어준다.

4. 딥러닝과 머신러닝의 차이점은 무엇인가?
- 머신러닝은 학습에 필요한 데이터들을 수동으로 제공해야 하나
딥러닝은 분류에 사용할 데이터들을 스스로 학습할 수 있음

5. Classification과 Regression의 주된 차이점은?
- Classification은 예측값으로 이산적인 값을 출력하며 관계성이 없다.
Regression은 예측값으로 연속적인 값을 출력하며 관계성이 있다.

6. 머신러닝에서 차원의 저주(curse of dimensionality)란?
- 특징의 수가 늘어날수록 데이터 간의 밀도가 급격히 감소하고, 
이로인해 모델의 성능이 떨어지는 현상.
높은 차원에서는 데이터가 Sparse 해져서 학습이 더욱 어려워짐..

7. Dimensionality Reduction는 왜 필요한가?
- 차원을 줄임으로써 불필요한 정보나 노이즈를 제거하여 모델 학습의 성능을 높이기 위함.

8. Ridge와 Lasso의 공통점과 차이점? (Regularization, 규제 , Scaling)
- 공통점 : 둘 다 규제(Regularization)를 이용한 회귀 모델이며 과적합 방지가 목적
- 차이점 : Ridge는 L2 규제 (가중치를 0에 가깝게 축소), Lasso는 L1 규제 (일부 가중치를 정확히 0으로 만듦)

9. Overfitting vs. Underfitting
- 과대적합은 모델 학습이 너무 많이 돼서 발생하는 것 (Outlier과 같은 노이즈도 학습)
- 과소적합은 모델 학습이 충분히 되지 않아서 발생함 .. 

10. Feature Engineering과 Feature Selection의 차이점은?
- 전자는 원본 데이터를 가공하여 새로운 Feature을 만들어내는 작업.
- 후자는 이미 존재하는 Feature 중 중요하고 유용한 것만 골라내는 작업.

11. 전처리(Preprocessing)의 목적과 방법? (노이즈, 이상치, 결측치)
- 데이터 품질 향상을 목적으로 하며
    - 노이즈 처리 : 데이터의 노이즈 제거
    - 이상치 처리 : 이상치를 제거 혹은 다른 값으로 대체
    - 결측치 처리 : 결측치를 삭제하거나 다른 값으로 채워넣음

12. EDA(Explorary Data Analysis)란? 데이터의 특성 파악(분포, 상관관계)
- 데이터의 특성과 분포, 상관관계를 시각화 및 통계적으로 탐색하는 과정

13. 회귀에서 절편과 기울기가 의미하는 바는? 딥러닝과 어떻게 연관되는가?
- 절편 : 독립변수가 0일 때의 종속변수 값
- 기울기 : 독립변수가 한 단위 증가할 때 종속변수가 얼마나 변하는지 나타냄
- 딥러닝에서 각 뉴런은 입력과 가중치(기울기), 바이어스(절편)를 이용하여 출력을 계산함

14. 교차검증, K-fold 교차검증의 의미와 차이
- 교차검증 : 데이터셋을 여러 번 나누어 반복 평가하여 모델 성능의 안정성을 검증하는 방법
- K-fold 교차검증 : 데이터를 K개로 나누고, 한 조각씩 번갈아 검증용으로 사용하여 평가

15. 하이퍼파라미터 튜닝이란 무엇인가?
- 머신러닝 모델의 성능에 영향을 주는 파라미터를 최적화하는 과정

16. 결정트리에서 불순도(Impurity) – 지니 계수(Gini Index)란 무엇인가?
- 불순도 : 트리 내의 클래스 혼합 정도
- 지니 계수 : 노드에서 클래스의 혼합 정도를 측정하는 지표 (0이면 완전 순수 즉 한 클래스만 존재한다는 의미)

17. 앙상블이란 무엇인가?
- 여러 모델을 결합하여 단일 모델보다 성능을 높이는 기법 (Ex_랜덤 포레스트, 배깅)

18. 부트 스트랩핑(bootstraping)이란 무엇인가?
- 기존 데이터를 반복하여 무작위 추출(복원 추출)하여 여러 개의 다른 샘플 데이터셋을 만드는 방식

19. 배깅(Bagging)이란 무엇인가?
- 부트스트랩을 통해 여러 데이터셋을 만든 뒤 독립적으로 모델 학습 후 결과를 결합

20. 주성분 분석 (PCA) 이란 무엇인가?
- 데이터의 주요 특징을 유지하면서 고차원의 데이터를 저차원으로 축소하는 방법.
```
