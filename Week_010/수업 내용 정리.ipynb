인공지능개론 
(참고)
```
  def split_sequence(sequence, n_steps):

    X, y = [], []

    for i in range(len(sequence) - n_steps):

        # 입력 시퀀스와 다음 값 분리

        seq_x = sequence[i:i + n_steps]

        seq_y = sequence[i + n_steps]

        X.append(seq_x)

        y.append(seq_y)

    return np.array(X), np.array(y)
```
      
- 1. Prompt Engineering : more detailed
프롬프트 엔지니어링은 대규모 언어 모델과 시각-언어 모델의 출력을 최적화하기 위해 입력 프롬프트를 설계하고 구조화하는 기술이다

- 2. partner -> AI not human (Bias에 빠진다 / 여러가지 다양한 관점 필요)

- 3. creative 


** 9장
CNN : 정보의 보존 (합성곱과 필터를 이용해서 Local Feature 추출) / 현재
(연산이 더 많아지므로 컨볼루션 풀링 ㄱㄱ)
- 인접한 공간 관계성 보존
vs 
Dense Layer (full connect layer) : 경우의 수를 다 연결 / 현재
- 인접한 픽셀의 관계성을 잃게 됨
**
순환 신경망 : 이전 시점과 다음 시점을 고려함 (CNN, Dense와 다름)
**

보폭 (Stride) : 커널을 적용하는 거리 *얼마나 이동할 것인가

패딩 (Padding) : 어디에서 움직일 것인가
ㄴ Valid : 이미지 안에서만 움직임
ㄴ Same : 이미지 밖에서만 움직임

풀링 (Pooling) : 정보의 축약 / 정보의 이동성 불변

CF 계산

p.382 : 9번 10번 풀어보기

** 10장
data argumentation : 한정된 데이터에서 여러 가지로 변형된 데이터를 만들어내는 기법이다. 
(어려운 이유 : 특징을 유지하면서 다양성 지속성 역시 유지해야한다)
ㄴ Labeling 비용이 너무 많이 소모됨
ㄴ Bias 역시 존재

pre-trained learning : 하나의 문제에 대해 학습한 신경망의 모델과 가중치를, 새로운 문제에 적용하는 것이다.
(이미 만들어진 모델, weight를 사용)

fine tuning : 사전 훈련된 모델의 가중치가 새로운 데이터에 대해 훈련되는 전이학습에 대한 접근 방식이다

CNN 입력을 위해 sample, feature
ex) (1200, 8) -> reshape하면 . . . flatten해지면 dense layer 쓰는 거랑 똑같애 . .
영상은 CNN 입력이 자연스레 됨

split_sequence -> 회귀
